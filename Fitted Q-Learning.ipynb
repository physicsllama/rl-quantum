{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q-Fitted Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1p15M3zwEdSlWgoXNOQNLWULqifyf9AMD",
      "authorship_tag": "ABX9TyNdn3XqAaiqBuuOdvgd2ZdS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/physicsllama/rl-quantum/blob/main/Fitted%20Q-Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implements fitted Q-learning"
      ],
      "metadata": {
        "id": "cJXwUOKuBGyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cmath\n",
        "import random\n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box, Dict\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout"
      ],
      "metadata": {
        "id": "TgSqlx6gpwur"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the qubit environement"
      ],
      "metadata": {
        "id": "G-Fydmjdlz2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qubit_eps = 0.01\n",
        "\n",
        "# Defining parts of the environment to deal with \"continuous\" variables (angles)\n",
        "samples = 20\n",
        "theta = np.linspace(0, np.pi, samples)\n",
        "phi = np.linspace(0, 2*np.pi, samples)\n",
        "\n",
        "# Fixed initial and final angles. Use theta1 only for initial testing.\n",
        "theta1 = random.choice(theta)\n",
        "phi1 = random.choice(phi)\n",
        "theta2 = random.choice(theta)\n",
        "phi2 = random.choice(phi)\n",
        "\n",
        "final_qubit = np.array([np.cos(theta2 / 2), np.exp(1j * phi2) * np.sin(theta2 / 2)])\n",
        "\n",
        "class QubitUnitary(Env):\n",
        "    def __init__(self):\n",
        "        # What we can observe: a single qubit, # characterized by 2 real angles on the Bloch sphere.\n",
        "        self.observation_space = Box(low=np.array([0, 0]), \n",
        "                                     high=np.array([np.pi, 2*np.pi]), shape=(2,))\n",
        "        \n",
        "        # What actions we can take: choose a unitary along an axis (y or z) \n",
        "        # and a real angle of rotation around that axis.\n",
        "        self.action_space = Dict({\"axis\": Discrete(2),\n",
        "                                  \"angle\": Box(low=0, high=2*np.pi, shape=(1,))})\n",
        "        \n",
        "        #Starting qubit. Can be the same every time, or different every time.\n",
        "        self.theta = theta1\n",
        "        self.phi = phi1\n",
        "        self.state = np.array([self.theta, self.phi])\n",
        "        self.qubit = np.array([np.cos(self.theta/2), np.exp(1j*self.phi)*np.sin(self.theta/2)])\n",
        "        \n",
        "        # Maximum number of unitaries before resetting\n",
        "        self.max_unitaries = 10\n",
        "    \n",
        "    def rot(self, axis, angle):\n",
        "        # If axis = 0, rotate y. if axis = 1, rotate z. Return the unitary for rotation along correct axis and angle.\n",
        "        if axis == 0:\n",
        "          return np.array([[np.cos(angle / 2), -np.sin(angle / 2)], [np.sin(angle / 2), np.cos(angle / 2)]])\n",
        "        elif axis == 1:\n",
        "          return np.array([[np.exp(-1j * angle / 2), 0], [0, np.exp(1j * angle / 2)]])\n",
        "        else:\n",
        "          return None\n",
        "\n",
        "    def qubit_fidelity(self, qubit1, qubit2):\n",
        "      return np.dot(qubit1, np.conjugate(qubit2)) * np.dot(np.conjugate(qubit1),qubit2)\n",
        "\n",
        "    def step(self, action):\n",
        "        # Update the qubit depending on what action we took\n",
        "        self.qubit = np.dot(self.rot(action[\"axis\"], action[\"angle\"][0]), self.qubit)\n",
        "\n",
        "        # Update parameters and state\n",
        "        self.theta = 2 * np.arccos(np.abs(self.qubit[0])-0.0001)\n",
        "        self.phi = (cmath.phase(self.qubit[1]) - cmath.phase(self.qubit[0]))%(2*np.pi)\n",
        "        self.state = [self.theta, self.phi]\n",
        "\n",
        "        # Decrease unitaries remaining\n",
        "        self.max_unitaries -= 1\n",
        "\n",
        "        # Reward step. Use criterion of distance to final qubit. This part can be experimented with.\n",
        "        if self.qubit_fidelity(self.qubit, final_qubit) > (1 - qubit_eps):\n",
        "            reward = 10\n",
        "        else:\n",
        "            reward = -1\n",
        "            \n",
        "        # Check if we've used up all unitaries:\n",
        "        if self.qubit_fidelity(self.qubit,final_qubit)>(1-qubit_eps) or self.max_unitaries<=0:\n",
        "            done = True\n",
        "        else:\n",
        "            done = False\n",
        "        # Maybe use info for rendering!\n",
        "        info = {}\n",
        "\n",
        "        return self.state, reward, done, info\n",
        "\n",
        "    def render(self):\n",
        "        pass\n",
        "\n",
        "    def reset(self):\n",
        "        # Reset qubit to initial state.\n",
        "        self.theta = random.choice(theta)\n",
        "        self.phi = random.choice(phi)\n",
        "        #self.theta = theta1\n",
        "        #self.phi = phi1\n",
        "        self.state = np.array([self.theta, self.phi])\n",
        "        self.qubit = np.array([np.cos(self.theta/2), np.exp(1j*self.phi)*np.sin(self.theta/2)])\n",
        "\n",
        "        # Reset max number of unitaries\n",
        "        self.max_unitaries = 10"
      ],
      "metadata": {
        "id": "vyRq9td1l2eW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = QubitUnitary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaM3kqMlnltO",
        "outputId": "89bb189e-287b-4aae-906b-fa6baa2cd3ff"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural network for learning Q from data"
      ],
      "metadata": {
        "id": "Y1wxSEaGnrL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model. Another possibility: have the model be outside, and just re-train or something like that as we expand data? (Instead of training from scratch every time.)\n",
        "\n",
        "def train_Q(data_x, data_y):\n",
        "  '''\n",
        "  Trains a neural network to find the value function Q(s, a).\n",
        "  data_x must be an array of length N containing tuples of the form [s1, s2, a1, a2_1, a2_2, a2_3] where a2_i is a one-hot encoding of discrete a2 variables.\n",
        "  data_y must be an array of length N containing numbers Q, corresponding to each tuple.\n",
        "  Test out on simple case before trying it for real!\n",
        "  '''\n",
        "  #data_size = np.shape(data_x)[0]\n",
        "\n",
        "  # Normalize data. Use one-hot encoding to turn discrete axes into appropriate variables.\n",
        "\n",
        "  '''\n",
        "  #Start defining the input tensor:\n",
        "  inpTensor = Input((6,))   \n",
        "\n",
        "  #create the layers and pass them the input tensor to get the output tensor:    \n",
        "  hidden1Out = Dense(units=3)(inpTensor)       \n",
        "  finalOut = Dense(units=1)(hidden1Out)   \n",
        "\n",
        "  #define the model's start and end points    \n",
        "  model = Model(inpTensor,finalOut)\n",
        "\n",
        "  '''\n",
        "  # Set up neural network\n",
        "  model = Sequential()\n",
        "  model.add(Dense(5, input_shape=(5,), activation = 'relu')) \n",
        "  model.add(Dense(5, activation = 'relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(6, activation = 'relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  # Compile model.\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=0.2) # Adjust parameters as needed. \n",
        "  model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "  # Fit the model.\n",
        "  model.fit(data_x, data_y) # Set verbose = 0 if I'm not interested in progress updates. Play with batch size, etc.\n",
        "\n",
        "  # Make a prediction; will return model, and need to call function.predict(x) to find Q. Might be better to simply define model = function(data), and use that model to predict in main code.\n",
        "  return model"
      ],
      "metadata": {
        "id": "980rFoXsoBtB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RL algorithm for Q-learning"
      ],
      "metadata": {
        "id": "Aq8zP6GMn4KQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_x_data = []\n",
        "for i in range(samples):\n",
        "  for j in range(samples):\n",
        "    for k in range(samples):\n",
        "      for l in [0,1]:\n",
        "          full_x_data.append(np.array([theta[i] / np.pi, phi[j] / (2.0 * np.pi), phi[k] / (2.0 * np.pi), int(l==0), int(l==1)]))"
      ],
      "metadata": {
        "id": "Ooc0bg_N1QL7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q_Data = []\n",
        "# Q is organized as [theta, phi, angle, axis]\n",
        "Q_Full = np.zeros((samples **3 * 2,1))\n",
        "Q_Matrix = np.reshape(Q_Full, (samples,samples,samples,2,1))\n",
        "# Maybe class is better way to deal with Q_Data or Q_Full!"
      ],
      "metadata": {
        "id": "D7BsQmrT4adX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use epsilon-greedy strategy to explore space of possibilities and update Q values.\n",
        "def select_action(s, epsilon):\n",
        "  p = random.random()\n",
        "  if p < epsilon:\n",
        "    return env.action_space.sample()\n",
        "  else:\n",
        "    # Indices associated to s1, s2.\n",
        "    s1 = int( np.floor((samples-1)*s[0]/np.pi))\n",
        "    s2 = int( np.floor((samples-1)*s[1]/(2.0*np.pi)))\n",
        "    # Best index from argmax of q.\n",
        "    Q_Matrix = np.reshape(Q_Full, (samples,samples,samples,2,1))\n",
        "    best_index = np.unravel_index(Q_Matrix[s1][s2].argmax(), Q_Matrix[s1][s2].shape)\n",
        "    best_angle = phi[best_index[0]]\n",
        "    best_axis = best_index[1]\n",
        "    best_action = {'axis': best_axis, 'angle': [best_angle]}\n",
        "    return best_action"
      ],
      "metadata": {
        "id": "rzY4KHPe4qFj"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update Q step.\n",
        "def update_Q(s, a, alpha, gamma):\n",
        "  # Indices corresponding to s, a.\n",
        "  s1 = int( np.floor((samples-1)*s[0]/np.pi))\n",
        "  if s1 >= samples or s1 <0:\n",
        "    print('Disaster! Value of s1 is' + str(s1))\n",
        "    print(s[0])\n",
        "  s2 = int( np.floor((samples-1)*s[1]/(2.0*np.pi)))\n",
        "  if s2 >= samples or s1 <0:\n",
        "    print('Disaster! Value of s2 is' + str(s2))\n",
        "    print(s[1])\n",
        "  a1 = int( np.floor((samples-1)*a['angle'][0]/(2.0*np.pi)))\n",
        "  a2 = a['axis']\n",
        "  # Take step, find new indices.\n",
        "  new_s, reward, done, info = env.step(a)\n",
        "  new_s1 = int( np.floor((samples-1)*new_s[0]/np.pi)) \n",
        "  if new_s1 >= samples or new_s1 <0:\n",
        "    print('Disaster! Value of new s1 is' + str(new_s1))\n",
        "    print(new_s[0])\n",
        "  new_s2 = int( np.floor((samples-1)*new_s[1]/(2.0*np.pi))) \n",
        "  if new_s2 >= samples or new_s2 <0:\n",
        "    print('Disaster! Value of new s2 is' + str(new_s2))\n",
        "    print(new_s[1])\n",
        "  old_Q = Q_Matrix[s1][s2][a1][a2]\n",
        "  Q_Matrix[s1][s2][a1][a2]=(1-alpha)*old_Q+alpha*(reward+gamma*np.max(Q_Matrix[new_s1][new_s2]))\n",
        "  Q_Data.append([s[0], s[1], a['angle'][0], a2, Q_Matrix[s1][s2][a1][a2]])\n",
        "  return done"
      ],
      "metadata": {
        "id": "8rBbHCIg5H0U"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing data for neural network"
      ],
      "metadata": {
        "id": "QM7hPInoY1dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update Data set with warm-up and random exploration. Set epsilon to be close to 1.\n",
        "warmup_steps = 5000\n",
        "counter = 0\n",
        "Q_Data = []\n",
        "while warmup_steps > 0:\n",
        "  env.reset()\n",
        "\n",
        "  # Now run loop where we get to explore until done! So 10 unitaries essentially. Set reward to be 0 initially.\n",
        "  Done = False\n",
        "\n",
        "  while not Done:\n",
        "    counter += 1\n",
        "    s = env.state\n",
        "    action = select_action(s, 0.99)\n",
        "    Done = update_Q(s, action, 0.99, 0.5) # Tweak alpha and gamma here! \n",
        "\n",
        "  warmup_steps -= 1\n",
        "\n",
        "print(counter)\n",
        "print(np.shape(Q_Data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q23WsAZsc4FV",
        "outputId": "24ea456c-d50e-4403-88dd-4bc1d9bff7f1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48326\n",
            "(48326, 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:1970: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = asarray(a).shape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write data in friendly way for neural network. Normalize data, use one-hot encoding for discrete variables.\n",
        "def translate_data(dat):\n",
        "  training_x = []\n",
        "  training_y = []\n",
        "  for i in range(np.shape(dat)[0]):\n",
        "    training_s1 = Q_Data[i][0] / (np.pi)\n",
        "    training_s2 = Q_Data[i][1] / (2 * np.pi)\n",
        "    training_a1 = Q_Data[i][2] / (2 * np.pi)\n",
        "    training_a21 = int(Q_Data[i][3] == 0)\n",
        "    training_a22 = int(Q_Data[i][3] == 1)\n",
        "    training_x.append([training_s1, training_s2, training_a1, training_a21, training_a22])\n",
        "    training_y.append(Q_Data[i][4])\n",
        "\n",
        "  training_x = np.array(training_x)\n",
        "  training_y = np.array(training_y)\n",
        "  return training_x, training_y"
      ],
      "metadata": {
        "id": "SX3wLdStY-ZS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "l30A_OIzY7AB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "burnin_runs = 1\n",
        "eps = 0.99\n",
        "while burnin_runs >= 0:\n",
        "\n",
        "  epochs = 100000\n",
        "  X = translate_data(Q_Data)\n",
        "  mod = train_Q(X[0], X[1])\n",
        "  x = np.expand_dims(full_x_data, axis=-1)\n",
        "  Q_Full = mod.predict(x)\n",
        "  Q_Matrix = np.reshape(Q_Full, (samples,samples,samples,2,1))\n",
        "  Q_Data = []\n",
        "  while epochs >= 0:\n",
        "    env.reset()\n",
        "    # Now run loop where we get to explore until done! So 10 unitaries essentially.\n",
        "    Done = False\n",
        "    while not Done:\n",
        "      s = env.state\n",
        "      action = select_action(s, eps)\n",
        "      Done = update_Q(s, action, 0.99, 0.5) # Tweak alpha and gamma here! \n",
        "\n",
        "    epochs -= 1\n",
        "  burnin_runs -= 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKl3zIZPFy48",
        "outputId": "fea7660a-26e2-46e6-d050-ac5315c2c497"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:1970: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = asarray(a).shape\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1511/1511 [==============================] - 3s 1ms/step - loss: 6.2744\n",
            "30048/30048 [==============================] - 43s 1ms/step - loss: 5.2821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do many loops of burnin at first! \n",
        "\n",
        "runs = 10\n",
        "eps = 0.7\n",
        "print(np.shape(Q_Data))\n",
        "while runs >= 0:\n",
        "\n",
        "  epochs = 50000\n",
        "  X = translate_data(Q_Data)\n",
        "  mod = train_Q(X[0], X[1])\n",
        "  x = np.expand_dims(full_x_data, axis=-1)\n",
        "  Q_Full = mod.predict(x)\n",
        "  Q_Matrix = np.reshape(Q_Full, (samples,samples,samples,2,1))\n",
        "  Q_Data = []\n",
        "  while epochs >= 0:\n",
        "    env.reset()\n",
        "    # Now run loop where we get to explore until done! So 10 unitaries essentially.\n",
        "    Done = False\n",
        "    while not Done:\n",
        "      s = env.state\n",
        "      action = select_action(s, eps)\n",
        "      Done = update_Q(s, action, 0.99, 0.5) # Tweak alpha and gamma here! \n",
        "\n",
        "    epochs -= 1\n",
        "\n",
        "  eps -= 0.1\n",
        "  runs -= 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dybAKnDi4AiA",
        "outputId": "d7d980d3-cedc-4bc6-ab0c-e48674844dd9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:1970: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = asarray(a).shape\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(961859, 5)\n",
            "30059/30059 [==============================] - 44s 1ms/step - loss: 6.9694\n",
            "13637/13637 [==============================] - 20s 1ms/step - loss: 4.4385\n",
            "13005/13005 [==============================] - 19s 1ms/step - loss: 6.1364\n",
            "12544/12544 [==============================] - 19s 1ms/step - loss: 12.0110\n",
            "12393/12393 [==============================] - 18s 1ms/step - loss: 6.2702\n",
            "12167/12167 [==============================] - 18s 1ms/step - loss: 8.2505\n",
            "11916/11916 [==============================] - 17s 1ms/step - loss: 9.2427\n",
            "11947/11947 [==============================] - 18s 1ms/step - loss: 3.4816\n",
            "15092/15092 [==============================] - 22s 1ms/step - loss: 0.7346\n",
            "15099/15099 [==============================] - 22s 1ms/step - loss: 1.0602\n",
            "15122/15122 [==============================] - 22s 1ms/step - loss: 0.8792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "S1K90k5QmBYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total = 1000\n",
        "numb_yes_training = []\n",
        "\n",
        "while total >= 0:  \n",
        "  env.reset()\n",
        "\n",
        "  Done = False\n",
        "  counter = 0\n",
        " \n",
        "  while not Done:\n",
        "    counter += 1\n",
        "    s = env.state\n",
        "    #print(env.qubit)\n",
        "    action = select_action(s, 0)\n",
        "    st, r, Done, info = env.step(action)\n",
        "    #print(env.qubit)\n",
        "    #print(action)\n",
        "    \n",
        "  total -= 1\n",
        "  \n",
        "  numb_yes_training.append(counter)\n",
        "\n",
        "success = 0\n",
        "for i in numb_yes_training:\n",
        "  if i <=9: #WHY IS TWO ENOUGH? \n",
        "    success += 1\n",
        "\n",
        "print(success / 1000)"
      ],
      "metadata": {
        "id": "ZfNoxWj1bFv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82fede8c-bc4b-48ef-c267-a800a2835735"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "txgIpVLS6sHK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}